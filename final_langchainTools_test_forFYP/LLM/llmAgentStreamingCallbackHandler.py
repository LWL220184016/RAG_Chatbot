from langchain.callbacks.base import BaseCallbackHandler

class LLMAgentStreamingCallbackHandler(BaseCallbackHandler):
    def __init__(self, queue):
        self.queue = queue
        self.full_response = ""  # Áî®‰∫éÁºìÂ≠òÂÆåÊï¥ÂìçÂ∫î
        self.is_agent_action = False
        self.token_window = []  # ÊªëÂä®Á™óÂè£
    
    def on_llm_new_token(self, token: str, **kwargs) -> None:
        # ÊµÅÂºèËæìÂá∫ÊØè‰∏™ TokenÔºàOllama ÁöÑ token ÂèØËÉΩÂåÖÂê´Ê†ºÂºèÂ≠óÁ¨¶Ôºâ
        self.full_response += token
        print(f"\033[95m{token}\033[0m", end="", flush=True)  # Á¥´Ëâ≤È´ò‰∫ÆËæìÂá∫

        # Êõ¥Êñ∞ÊªëÂä®Á™óÂè£
        self.token_window.append(token)
        if len(self.token_window) > 4:  # ÂÅáËÆæ "Final Answer" ÊòØÁî± 3 ‰∏™ token ÁªÑÊàê
            self.token_window.pop(0)

        # Ê£ÄÊü•ÊªëÂä®Á™óÂè£‰∏≠ÁöÑ token ÊòØÂê¶ÂåπÈÖç "Final Answer"
        print("----------------" + "".join(self.token_window) + "----------------")
        if "".join(self.token_window) == ' "Final Answer",\n':
            self.is_agent_action = True
            print("\n\033[91mü§ñ Action: Final Answer\033[0m") #

            self.queue.put(token)

# ```json
# {
#   "action": "Final Answer",
#   "action_input": "ÊúÄÊñ∞ÁöÑÁæéÂõΩÊÄªÁªüÊòØ‰πî¬∑ÊãúÁôªÔºàJoe BidenÔºâÔºå‰ªñËá™2021Âπ¥1Êúà20Êó•Ëµ∑ÊãÖ‰ªªËøô‰∏ÄËÅå‰Ωç„ÄÇ"
# }
# ```

    def on_agent_action(self, action, **kwargs):
        # Agent Ë∞ÉÁî®Â∑•ÂÖ∑Êó∂Ëß¶Âèë
        # print(f"\n\033[94mü§ñ Action: {action.log}\033[0m")  # ËìùËâ≤È´ò‰∫Æ
        # print(f"\n\033[91mü§ñ Action: {action.log}\033[0m")  # Á∫¢Ëâ≤È´ò‰∫Æ
        # self.queue.put(f"\nAction: {action.log}")
        pass

    def on_tool_end(self, output: str, **kwargs):
        # Â∑•ÂÖ∑ÊâßË°åÂÆåÊàê
        # print(f"\n\033[93müîç Observation: {output}\033[0m")  # ÈªÑËâ≤È´ò‰∫Æ
        # print("on_tool_end called")
        # print(f"\n\033[38;5;208müîç Observation: {output}\033[0m")  # Ê©ôËâ≤È´ò‰∫Æ (256-color)
        # self.queue.put(f"\nObservation: {output}")
        pass

    def on_agent_finish(self, finish, **kwargs):
        # Agent ÂÆåÊàêÊâÄÊúâÊìç‰Ωú
        # print(f"\n\033[95m‚úÖ Final Answer: {finish.return_values['output']}\033[0m")
        # self.queue.put(f"\nFinal Result: {finish.return_values['output']}")
        # self.queue.put(None)  # ÁªìÊùü‰ø°Âè∑
        self.is_agent_action = False
        pass

# class QueueCallbackHandler(BaseCallbackHandler):
#     """Â∞ÜÂõûË∞ÉÊï∞ÊçÆÂ≠òÂÖ•ÈòüÂàó‰æõÁîüÊàêÂô®ËØªÂèñ"""
#     def __init__(self, queue):
#         self.queue = queue

#     def on_llm_new_token(self, token: str, **kwargs) -> None:
#         self.queue.put(token)

#     def on_agent_action(self, action, **kwargs):
#         self.queue.put(f"\nAction: {action.log}")

#     def on_tool_end(self, output: str, **kwargs):
#         self.queue.put(f"\nObservation: {output}")

#     def on_agent_finish(self, finish, **kwargs):
#         self.queue.put(f"\nFinal Result: {finish.return_values['output']}")
#         self.queue.put(None)  # ÁªìÊùü‰ø°Âè∑
