import openai
import os
from typing import Iterator

# è¨­ç½® API åŸºç¤ URL æŒ‡å‘æœ¬åœ° vLLM æœå‹™å™¨
# é€šå¸¸æœ¬åœ° vLLM æœå‹™é»˜èªåœ¨ 8000 ç«¯å£é‹è¡Œ
openai.base_url = "http://localhost:8000/v1/"

# å¯é¸: è¨­ç½®ä¸€å€‹è™›æ“¬çš„ API å¯†é‘°ï¼Œå°æ–¼æœ¬åœ° vLLM æœå‹™å¯èƒ½ä¸æ˜¯å¿…é ˆçš„
openai.api_key = "dummy-api-key"

# python -m vllm.entrypoints.openai.api_server     \
#         --model deepseek-ai/DeepSeek-R1-Distill-Qwen-7B     \
#         --port 8000     \
#         --gpu_memory_utilization 0.98     \
#         --quantization fp8     \
#         --max_model_len 80000

def generate_response_stream(prompt: str) -> Iterator[str]:
    """ä½¿ç”¨æœ¬åœ° vLLM æœå‹™ç”Ÿæˆæµå¼å›æ‡‰"""
    try:
        # ä½¿ç”¨æµå¼ API
        stream = openai.chat.completions.create(
            model="deepseek-ai/DeepSeek-R1-Distill-Qwen-7B", # vLLM æœå‹™ä¸­åŠ è¼‰çš„æ¨¡å‹åç¨±
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=50000,
            stream=True  # å•Ÿç”¨æµå¼è¼¸å‡º
        )
        
        # è™•ç†æµå¼éŸ¿æ‡‰
        collected_content = ""
        for chunk in stream:
            if chunk.choices and chunk.choices[0].delta.content:
                content_piece = chunk.choices[0].delta.content
                collected_content += content_piece
                yield content_piece
        
        return collected_content
    except Exception as e:
        yield f"éŒ¯èª¤: {str(e)}"

def generate_response(prompt: str) -> str:
    """ä½¿ç”¨æœ¬åœ° vLLM æœå‹™ç”Ÿæˆå®Œæ•´å›æ‡‰ (éæµå¼)"""
    collected_response = ""
    for chunk in generate_response_stream(prompt):
        collected_response += chunk
    return collected_response

# æ¸¬è©¦æµå¼è¼¸å‡ºçš„å‡½æ•¸
def test_stream(user_input):
    print(f"\n\033[38;5;208mğŸ˜„å•é¡Œ: {user_input}\033[0m")  # æ©™è‰²é«˜äº® (256-color)
    print(f"\n\033[38;5;46mğŸ¤–å›ç­”: \033[0m", end="", flush=True)  # é®®ç¶ è‰²
    for text_chunk in generate_response_stream(user_input):
        print(f"\033[38;5;46m{text_chunk}\033[0m", end="", flush=True)  # å»æ‰æ›è¡Œç¬¦è™Ÿ
    print()  # æœ€å¾Œæ·»åŠ ä¸€å€‹æ›è¡Œ

# æ¸¬è©¦å‡½æ•¸
if __name__ == "__main__":
    # é¸æ“‡æ¸¬è©¦æ–¹å¼ï¼šæµå¼æˆ–å®Œæ•´éŸ¿æ‡‰
    use_streaming = True
    
    user_input = "ä½ å¥½ï¼"
    if use_streaming:
        test_stream(user_input)
    else:
        response = generate_response(user_input)
        print(f"å•é¡Œ: {user_input}")
        print(f"å›ç­”: {response}")
    

    while True:
        user_input = input("User: ")
        if user_input == "exit":
            break
        if use_streaming:
            test_stream(user_input)
        else:
            response = generate_response(user_input)
            print(f"å•é¡Œ: {user_input}")
            print(f"å›ç­”: {response}")